{"cells":[{"cell_type":"code","execution_count":null,"id":"b114e5c3","metadata":{"id":"b114e5c3"},"outputs":[],"source":["import os\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"]},{"cell_type":"markdown","id":"06be70af","metadata":{"id":"06be70af"},"source":["### Loading the data"]},{"cell_type":"code","execution_count":null,"id":"54c5a24a","metadata":{"id":"54c5a24a"},"outputs":[],"source":["\n","# Define constants\n","train_dir = 'Corn/train/'\n","test_dir = 'Corn/test/'\n","batch_size = 32\n","num_classes = 4\n","input_shape = (250, 250, 3)  # Adjust according to your image dimensions\n","\n","# Function to filter images based on extensions\n","def filter_images_by_extension(directory):\n","    valid_extensions = ['.jpg', '.jpeg', '.png']\n","    image_files = []\n","    for root, _, files in os.walk(directory):\n","        for file in files:\n","            if any(file.lower().endswith(ext) for ext in valid_extensions):\n","                image_files.append(os.path.join(root, file))\n","    return image_files\n","\n","# Filter image files\n","train_image_files = filter_images_by_extension(train_dir)\n","test_image_files = filter_images_by_extension(test_dir)\n"]},{"cell_type":"code","execution_count":null,"id":"6eb00da9","metadata":{"id":"6eb00da9","outputId":"96705787-4dc5-45a5-9eb6-ef40aefb248d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 7316 validated image filenames belonging to 4 classes.\n","Found 1829 validated image filenames belonging to 4 classes.\n"]}],"source":["\n","# Create DataFrame for training and testing\n","train_df = pd.DataFrame({\n","    'filename': train_image_files,\n","    'class': [os.path.basename(os.path.dirname(path)) for path in train_image_files]\n","})\n","\n","test_df = pd.DataFrame({\n","    'filename': test_image_files,\n","    'class': [os.path.basename(os.path.dirname(path)) for path in test_image_files]\n","})\n","\n","# Data augmentation and normalization for training\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","# Normalization for testing\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Generating batches of training and testing data\n","train_generator = train_datagen.flow_from_dataframe(\n","    train_df,\n","    x_col='filename',\n","    y_col='class',\n","    target_size=(input_shape[0], input_shape[1]),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","test_generator = test_datagen.flow_from_dataframe(\n","    test_df,\n","    x_col='filename',\n","    y_col='class',\n","    target_size=(input_shape[0], input_shape[1]),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n"]},{"cell_type":"markdown","id":"5ac53f8f","metadata":{"id":"5ac53f8f"},"source":["### Training the model"]},{"cell_type":"code","execution_count":null,"id":"9f9e502c","metadata":{"id":"9f9e502c","outputId":"70039e32-7ed0-43f1-d20a-9cd2bb2e522c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","229/229 [==============================] - 184s 801ms/step - loss: 0.3889 - accuracy: 0.8472 - val_loss: 0.1793 - val_accuracy: 0.9311\n","Epoch 2/10\n","229/229 [==============================] - 203s 886ms/step - loss: 0.1620 - accuracy: 0.9374 - val_loss: 0.1556 - val_accuracy: 0.9399\n","Epoch 3/10\n","229/229 [==============================] - 205s 894ms/step - loss: 0.1420 - accuracy: 0.9478 - val_loss: 0.1272 - val_accuracy: 0.9568\n","Epoch 4/10\n","229/229 [==============================] - 207s 901ms/step - loss: 0.1185 - accuracy: 0.9554 - val_loss: 0.1200 - val_accuracy: 0.9574\n","Epoch 5/10\n","229/229 [==============================] - 203s 887ms/step - loss: 0.1288 - accuracy: 0.9549 - val_loss: 0.2056 - val_accuracy: 0.9185\n","Epoch 6/10\n","229/229 [==============================] - 202s 880ms/step - loss: 0.1156 - accuracy: 0.9535 - val_loss: 0.1092 - val_accuracy: 0.9612\n","Epoch 7/10\n","229/229 [==============================] - 210s 918ms/step - loss: 0.1041 - accuracy: 0.9615 - val_loss: 0.0942 - val_accuracy: 0.9705\n","Epoch 8/10\n","229/229 [==============================] - 205s 895ms/step - loss: 0.0846 - accuracy: 0.9672 - val_loss: 0.2309 - val_accuracy: 0.9163\n","Epoch 9/10\n","229/229 [==============================] - 204s 892ms/step - loss: 0.0892 - accuracy: 0.9676 - val_loss: 0.1399 - val_accuracy: 0.9508\n","Epoch 10/10\n","229/229 [==============================] - 203s 884ms/step - loss: 0.0779 - accuracy: 0.9712 - val_loss: 0.1155 - val_accuracy: 0.9634\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x153fb6350>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Define the model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(train_generator, epochs=10, validation_data=test_generator)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"8e44479c","metadata":{"id":"8e44479c","outputId":"28cf3a0f-a723-4dfd-8aa3-7449b2ddfa3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["58/58 [==============================] - 14s 235ms/step - loss: 0.1155 - accuracy: 0.9634\n","Test accuracy: 0.9633679389953613\n"]}],"source":["# Evaluate the model\n","test_loss, test_acc = model.evaluate(test_generator)\n","print('Test accuracy:', test_acc)"]},{"cell_type":"code","execution_count":null,"id":"74cb187c","metadata":{"id":"74cb187c"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import cv2"]},{"cell_type":"markdown","id":"5e2c8803","metadata":{"id":"5e2c8803"},"source":["### Saving the Model"]},{"cell_type":"code","execution_count":null,"id":"4b9dfade","metadata":{"id":"4b9dfade","outputId":"ce13393e-3db1-4039-e91e-cc6c6ef37668"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /var/folders/wc/4vhbxzyn749cv5d6p5s6nw100000gp/T/tmp7ny6gzjc/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /var/folders/wc/4vhbxzyn749cv5d6p5s6nw100000gp/T/tmp7ny6gzjc/assets\n","2024-04-19 15:00:31.223141: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n","2024-04-19 15:00:31.223154: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n","2024-04-19 15:00:31.223721: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wc/4vhbxzyn749cv5d6p5s6nw100000gp/T/tmp7ny6gzjc\n","2024-04-19 15:00:31.224397: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n","2024-04-19 15:00:31.224401: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wc/4vhbxzyn749cv5d6p5s6nw100000gp/T/tmp7ny6gzjc\n","2024-04-19 15:00:31.226752: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n","2024-04-19 15:00:31.227344: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n","2024-04-19 15:00:31.410000: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wc/4vhbxzyn749cv5d6p5s6nw100000gp/T/tmp7ny6gzjc\n","2024-04-19 15:00:31.417793: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 194073 microseconds.\n","2024-04-19 15:00:31.444399: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","Summary on the non-converted ops:\n","---------------------------------\n"," * Accepted dialects: tfl, builtin, func\n"," * Non-Converted Ops: 11, Total Ops 24, % non-converted = 45.83 %\n"," * 11 ARITH ops\n","\n","- arith.constant:   11 occurrences  (f32: 10, i32: 1)\n","\n","\n","\n","  (f32: 3)\n","  (f32: 2)\n","  (f32: 3)\n","  (f32: 1)\n","  (f32: 1)\n"]}],"source":["\n","# Convert the model to TensorFlow Lite format\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# Save the converted model to a file\n","with open('corn_disease.tflite', 'wb') as f:\n","    f.write(tflite_model)\n"]},{"cell_type":"code","execution_count":null,"id":"3e7b7f61","metadata":{"id":"3e7b7f61","outputId":"ea6376cc-1ce8-4c3f-fec6-cf44f16cbb98"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/student/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["model.save(\"corn_model.h5\")"]},{"cell_type":"markdown","id":"23017b92","metadata":{"id":"23017b92"},"source":["### Predictions"]},{"cell_type":"code","execution_count":null,"id":"40177b11","metadata":{"id":"40177b11","outputId":"86360bb2-62f0-4431-c1c2-26d24bf28fae"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 58ms/step\n","Predicted class: Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n","Prediction probabilities: [[1. 0. 0. 0.]]\n"]}],"source":["import numpy as np\n","from tensorflow.keras.preprocessing import image\n","\n","# Load the image you want to predict\n","img_path = 'cercospora.JPG'  # Provide the path to your image\n","img = image.load_img(img_path, target_size=(250, 250))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","img_array /= 255.  # Rescale pixel values to [0, 1]\n","\n","# Make prediction\n","prediction = model.predict(img_array)\n","predicted_class = np.argmax(prediction)\n","\n","# Map predicted class index to class label\n","class_labels = train_generator.class_indices\n","predicted_label = [k for k, v in class_labels.items() if v == predicted_class][0]\n","\n","print(\"Predicted class:\", predicted_label)\n","for i in range(0,4):\n","    prediction[0][i] = np.round((prediction[0][i]),2)\n","print(\"Prediction probabilities:\", prediction)\n"]},{"cell_type":"code","execution_count":null,"id":"a477aaa3","metadata":{"id":"a477aaa3","outputId":"1cfd855c-ee43-4ddc-fd19-2baf7df8f81f"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 26ms/step\n","Predicted class: Corn_(maize)___Common_rust_\n","Prediction probabilities: [[0. 1. 0. 0.]]\n"]}],"source":["# Load the image you want to predict\n","img_path = 'RS_Rust 1581.JPG'  # Provide the path to your image\n","img = image.load_img(img_path, target_size=(250, 250))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","img_array /= 255.  # Rescale pixel values to [0, 1]\n","\n","# Make prediction\n","prediction = model.predict(img_array)\n","predicted_class = np.argmax(prediction)\n","\n","# Map predicted class index to class label\n","class_labels = train_generator.class_indices\n","predicted_label = [k for k, v in class_labels.items() if v == predicted_class][0]\n","\n","print(\"Predicted class:\", predicted_label)\n","for i in range(0,4):\n","    prediction[0][i] = np.round((prediction[0][i]),2)\n","print(\"Prediction probabilities:\", prediction)\n"]},{"cell_type":"code","execution_count":null,"id":"9e81e2ab","metadata":{"id":"9e81e2ab","outputId":"3bf040c9-65c8-41c6-9d4c-fac63082faad"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 20ms/step\n","Predicted class: Corn_(maize)___healthy\n","Prediction probabilities: [[0. 0. 0. 1.]]\n"]}],"source":["# Load the image you want to predict\n","img_path = 'healthy.jpg'  # Provide the path to your image\n","img = image.load_img(img_path, target_size=(250, 250))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","img_array /= 255.  # Rescale pixel values to [0, 1]\n","\n","# Make prediction\n","prediction = model.predict(img_array)\n","predicted_class = np.argmax(prediction)\n","\n","# Map predicted class index to class label\n","class_labels = train_generator.class_indices\n","predicted_label = [k for k, v in class_labels.items() if v == predicted_class][0]\n","\n","print(\"Predicted class:\", predicted_label)\n","for i in range(0,4):\n","    prediction[0][i] = np.round((prediction[0][i]),2)\n","print(\"Prediction probabilities:\", prediction)\n"]},{"cell_type":"code","execution_count":null,"id":"23a8fb3c","metadata":{"id":"23a8fb3c","outputId":"05eb25a6-45d1-4c38-a2b0-940e6229be21"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 24ms/step\n","Predicted class: Corn_(maize)___Northern_Leaf_Blight\n","Prediction probabilities: [[0.06 0.   0.94 0.  ]]\n"]}],"source":["# Load the image you want to predict\n","img_path = 'leaf_blight.JPG'  # Provide the path to your image\n","img = image.load_img(img_path, target_size=(250, 250))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","img_array /= 255.  # Rescale pixel values to [0, 1]\n","\n","# Make prediction\n","prediction = model.predict(img_array)\n","predicted_class = np.argmax(prediction)\n","\n","# Map predicted class index to class label\n","class_labels = train_generator.class_indices\n","predicted_label = [k for k, v in class_labels.items() if v == predicted_class][0]\n","\n","print(\"Predicted class:\", predicted_label)\n","for i in range(0,4):\n","    prediction[0][i] = np.round((prediction[0][i]),2)\n","print(\"Prediction probabilities:\", prediction)\n"]},{"cell_type":"code","execution_count":null,"id":"d9aa655f","metadata":{"id":"d9aa655f"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}